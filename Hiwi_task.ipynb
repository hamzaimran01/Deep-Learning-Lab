{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hiwi_task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzaimran01/Deep-Learning-Lab/blob/master/Hiwi_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "w1_mfS8kvH7a",
        "colab_type": "code",
        "outputId": "51c4e0d9-9b02-425a-ae0b-dbe2a40700fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2434
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "!curl https://raw.githubusercontent.com/automl/smac3/master/requirements.txt | xargs -n 1 -L 1 pip install\n",
        "!pip install smac"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   220  100   220    0     0   1037      0 --:--:-- --:--:-- --:--:--  1037\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (40.9.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.6)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (1.16.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.18.1) (1.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.11.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: pynisher>=0.4.1 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.1) (5.4.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.1) (40.9.0)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.1) (0.14)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (0.4.10)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.6) (0.29.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.6) (1.16.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.6) (3.6.6)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.6) (2.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (0.20.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0) (1.16.2)\n",
            "Collecting pyrfr>=0.5.0\n",
            "  Using cached https://files.pythonhosted.org/packages/ed/0f/4d7e42a9dfef3a1898e03cffa8f1cfcd1f96507d718808b2db584c6f8401/pyrfr-0.8.0.tar.gz\n",
            "Building wheels for collected packages: pyrfr\n",
            "  Building wheel for pyrfr (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/61/1a/d2/b5aee388a492a01946143d3c976b2ca810af537480e1f16999\n",
            "Successfully built pyrfr\n",
            "Installing collected packages: pyrfr\n",
            "Successfully installed pyrfr-0.8.0\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (1.8.5)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.18.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from sphinx) (40.9.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.1.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx) (1.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx) (1.1.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx) (0.7.12)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx) (19.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx) (1.2.1)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx) (0.14)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx) (2.10.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from sphinx) (1.11.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx) (1.22)\n",
            "Requirement already satisfied: pytz>=0a in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->sphinx) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->sphinx) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx) (1.1.1)\n",
            "Requirement already satisfied: sphinx_rtd_theme in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from sphinx_rtd_theme) (1.8.5)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (0.14)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (1.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (2.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (1.11.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (40.9.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (1.2.1)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (2.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (19.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (2.1.3)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->sphinx_rtd_theme) (2.6.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->sphinx_rtd_theme) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->sphinx_rtd_theme) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->sphinx_rtd_theme) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->sphinx_rtd_theme) (2019.3.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->sphinx_rtd_theme) (1.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->sphinx->sphinx_rtd_theme) (2.4.0)\n",
            "Requirement already satisfied: pytz>=0a in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->sphinx->sphinx_rtd_theme) (2018.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.12.5)\n",
            "Requirement already satisfied: nose>=1.3.0 in /usr/local/lib/python3.6/dist-packages (1.3.7)\n",
            "Requirement already satisfied: pyDOE in /usr/local/lib/python3.6/dist-packages (0.3.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pyDOE) (1.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyDOE) (1.16.2)\n",
            "Collecting sobol_seq\n",
            "Installing collected packages: sobol-seq\n",
            "Successfully installed sobol-seq-0.1.2\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.23.4)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy->statsmodels) (1.16.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->statsmodels) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->statsmodels) (2.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy->statsmodels) (1.11.0)\n",
            "Requirement already satisfied: emcee>=2.1.0 in /usr/local/lib/python3.6/dist-packages (2.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from emcee>=2.1.0) (1.16.2)\n",
            "Requirement already satisfied: george in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from george) (1.16.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from george) (1.2.1)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.6/dist-packages (from george) (2.2.4)\n",
            "Collecting smac\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from smac) (0.29.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from smac) (1.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from smac) (40.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from smac) (5.4.8)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from smac) (1.8.5)\n",
            "Requirement already satisfied: nose>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from smac) (1.3.7)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from smac) (0.20.3)\n",
            "Requirement already satisfied: pyrfr>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from smac) (0.8.0)\n",
            "Requirement already satisfied: pynisher>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from smac) (0.5.0)\n",
            "Requirement already satisfied: sobol-seq in /usr/local/lib/python3.6/dist-packages (from smac) (0.1.2)\n",
            "Requirement already satisfied: emcee>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from smac) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from smac) (1.16.2)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from smac) (0.4.10)\n",
            "Requirement already satisfied: george in /usr/local/lib/python3.6/dist-packages (from smac) (0.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from smac) (1.11.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from smac) (0.8.0)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.6/dist-packages (from smac) (0.4.3)\n",
            "Requirement already satisfied: pyDOE in /usr/local/lib/python3.6/dist-packages (from smac) (0.3.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from smac) (0.12.5)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (2.10.1)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (2.6.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (1.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (1.1.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (2.18.4)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (2.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (19.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (0.14)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (0.7.12)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.6->smac) (3.6.6)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.6->smac) (2.4.0)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.6/dist-packages (from george->smac) (2.2.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from statsmodels->smac) (0.23.4)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.6/dist-packages (from statsmodels->smac) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac) (1.1.1)\n",
            "Requirement already satisfied: pytz>=0a in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->sphinx->smac) (2018.9)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->statsmodels->smac) (2.5.3)\n",
            "Installing collected packages: smac\n",
            "Successfully installed smac-0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YjuwNW9OEPys",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import typing\n",
        "\n",
        "\n",
        "\n",
        "from smac.facade.borf_facade import BORF\n",
        "from smac.scenario.scenario import Scenario\n",
        "from smac.configspace import ConfigurationSpace\n",
        "from smac.runhistory.runhistory import RunKey\n",
        "from smac.tae.execute_func import ExecuteTAFuncArray\n",
        "\n",
        "from ConfigSpace.hyperparameters import UniformFloatHyperparameter\n",
        "from smac.facade.func_facade import fmin_smac\n",
        "def branin(x):\n",
        "    x1 = x[0]\n",
        "    x2 = x[1]\n",
        "    a = 1.\n",
        "    b = 5.1 / (4.*np.pi**2)\n",
        "    c = 5. / np.pi\n",
        "    r = 6.\n",
        "    s = 10.\n",
        "    t = 1. / (8.*np.pi)\n",
        "    ret = a*(x2-b*x1**2+c*x1-r)**2+s*(1-t)*np.cos(x1)+s\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DK4WoUtvjJ2q",
        "colab_type": "code",
        "outputId": "d14b6900-8a17-41cc-9d6c-27e095315893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# we will verify that GPU is enabled for this notebook\n",
        "# following should print: CUDA is available!  Training on GPU ...\n",
        "# \n",
        "# if it prints otherwise, then you need to enable GPU: \n",
        "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K26zReUxxrd6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class KMNIST(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for use with pytorch for the Kuzushiji-MNIST dataset as given in\n",
        "    Deep Learning for Classical Japanese Literature. Tarin Clanuwat et al. arXiv:1812.01718\n",
        "\n",
        "    Kuzushiji-MNIST contains 70,000 28x28 grayscale images spanning 10 classes (one from each column of hiragana),\n",
        "    and is perfectly balanced like the original MNIST dataset (6k/1k train/test for each class).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_dir='.', train: bool = True, transform=None):\n",
        "        \"\"\"\n",
        "        :param data_dir: Directory of the data\n",
        "        :param train: Use training or test set\n",
        "        :param transform: pytorch transforms for data augmentation\n",
        "        \"\"\"\n",
        "\n",
        "        self.__urls = [\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz',\n",
        "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz',\n",
        "        ]\n",
        "\n",
        "        t_str = 'train' if train else 'test'\n",
        "        imgs_fn = 'kmnist-{}-imgs.npz'.format(t_str)\n",
        "        labels_fn = 'kmnist-{}-labels.npz'.format(t_str)\n",
        "\n",
        "        if not os.path.exists(data_dir):\n",
        "            os.mkdir(os.path.abspath(data_dir))\n",
        "        if not os.path.exists(os.path.abspath(os.path.join(data_dir, imgs_fn))):\n",
        "            self.__download(os.path.abspath(data_dir))\n",
        "\n",
        "        imgs_fn = os.path.abspath(os.path.join(data_dir, imgs_fn))\n",
        "        labels_fn = os.path.abspath(os.path.join(data_dir, labels_fn))\n",
        "       \n",
        "        self.images = np.load(imgs_fn)['arr_0']\n",
        "        self.labels = np.load(labels_fn)['arr_0']\n",
        "        self.n_classes = len(np.unique(self.labels))\n",
        "       \n",
        "        \n",
        "        self.class_labels, self.class_frequency = np.unique(self.labels, return_counts=True)\n",
        "        self.class_frequency = self.class_frequency / np.sum(self.class_frequency)\n",
        "        self.data_dir = data_dir\n",
        "        self.img_rows = 28\n",
        "        self.img_cols = 28\n",
        "        self.channels = 1  # only gray scale\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "       \n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):#image size is 28*28*1\n",
        "        image = np.expand_dims(self.images[idx], axis=-1)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "            \n",
        "\n",
        "        label = np.int(self.labels[idx])\n",
        "       # var=torch.tensor(image)\n",
        "        #a = np.squeeze(var)\n",
        "        #plt.imshow(a, cmap='Greys')\n",
        "        #print(a.size())\n",
        "       \n",
        "        return image, label\n",
        "\n",
        "    def __download(self, data_dir):\n",
        "        print('Datadir', data_dir)\n",
        "   \n",
        "        for url in self.__urls:\n",
        "            fn = os.path.basename(url)\n",
        "            req = requests.get(url, stream=True)\n",
        "            print('Downloading {}'.format(fn))\n",
        "            with open(os.path.join(data_dir, fn), 'wb') as fh:\n",
        "                for chunck in req.iter_content(chunk_size=1024):\n",
        "                    if chunck:\n",
        "                        fh.write(chunck)\n",
        "            print('done')\n",
        "        print('All files downloaded')\n",
        "        \n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRUl0DCwqJl-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tensor shape and distributed into train and test sets\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_set=torchvision.datasets.KMNIST(root='./KMNIST', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "test_set = torchvision.datasets.KMNIST(root='./KMNIST', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jfOkgH7cdcMn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#basically uses the data in the iteration\n",
        "def get_train_loader(batch_size):\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,sampler=train_sampler)\n",
        "    return(train_loader)\n",
        "  \n",
        "def get_test_loader(batch_size):\n",
        "    test_loader=torch.utils.data.DataLoader(test_set, batch_size=batch_size,shuffle=False)\n",
        "    return(test_loader)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zypm_BWPboj6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#forming samplers of train,test \n",
        "\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "#Training\n",
        "n_training_samples = 30000\n",
        "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
        "\n",
        "\n",
        "\n",
        "#Test\n",
        "n_test_samples = 1000\n",
        "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ly_8qjmJnp9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(torch.nn.Module):\n",
        "    \n",
        "    #Our batch shape for input x is (3, 32, 32)\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        \n",
        "        #Input channels = 1, output channels = 18\n",
        "        self.conv1 = torch.nn.Conv2d(1, 18, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        \n",
        "        #4608 input features, 64 output features (see sizing flow below)\n",
        "        self.fc1 = torch.nn.Linear(18 * 14 * 14, 64)\n",
        "        \n",
        "        #64 input features, 10 output features for our 10 defined classes\n",
        "        self.fc2 = torch.nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "      \n",
        "        \n",
        "        \n",
        "        #Computes the activation of the first convolution\n",
        "        #Size changes from (3, 28, 28) to (18, 28, 28)\n",
        "        x = F.relu(self.conv1(x))\n",
        "     \n",
        "        \n",
        "        #Size changes from (18, 28, 28) to (18, 14, 14)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        \n",
        "        #Reshape data to input to the input layer of the neural net\n",
        "        #Size changes from (18, 14, 14) to (1, 4608)\n",
        "        #Recall that the -1 infers this dimension from the other given dimension\n",
        "        x = x.view(-1, 18 * 14 *14)\n",
        "        \n",
        "        #Computes the activation of the first fully connected layer\n",
        "        #Size changes from (1, 4608) to (1, 64)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        \n",
        "        #Computes the second fully connected layer (activation applied later)\n",
        "        #Size changes from (1, 64) to (1, 10)\n",
        "        x = self.fc2(x)\n",
        "        return(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YhdtUQYJ-I4l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def createLossAndOptimizer(net, learning_rate=0.001):\n",
        "    \n",
        "    #Loss function\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    \n",
        "    #Optimizer\n",
        "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    \n",
        "    return(loss, optimizer)\n",
        "  \n",
        "  \n",
        "  \n",
        "def SMAC(net,func):  \n",
        "  x, cost, _ = fmin_smac(func=branin,x0=[0, 0],bounds=[(-5, 10), (0, 15)],maxfun=500,rng=3)        \n",
        "  print(\"Optimum at {} with cost of {}\".format(x, cost)),\n",
        "  \n",
        "  return x,cost,_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9cp-SkFcntB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
        "    \n",
        "    #Print all of the hyperparameters of the training iteration:\n",
        "    print(\"===== HYPERPARAMETERS =====\")\n",
        "    print(\"batch_size=\", batch_size)\n",
        "    print(\"epochs=\", n_epochs)\n",
        "    print(\"learning_rate=\", learning_rate)\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    #Get training data\n",
        "    train_loader = get_train_loader(batch_size)\n",
        "    n_batches = len(train_loader)\n",
        "    #print(\"the number of batches are \",n_batches)\n",
        "    \n",
        "    \n",
        "    #Create our loss and optimizer functions\n",
        "    optimizer,loss = SMAC(net, learning_rate)\n",
        "    \n",
        "    #Time for printing\n",
        "    training_start_time = time.time()\n",
        "    \n",
        "    #Loop for n_epochs\n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        print_every = n_batches // 10\n",
        "        start_time = time.time()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            \n",
        "            #Get inputs\n",
        "            inputs, labels = data\n",
        "           \n",
        "           \n",
        "            \n",
        "            #Wrap them in a Variable object\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            #Set the parameter gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            #Forward pass, backward pass, optimize\n",
        "            outputs = net(inputs)\n",
        "            loss_size = loss(outputs, labels)\n",
        "            loss_size.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            #Print statistics\n",
        "            running_loss += loss_size.item()\n",
        "            total_train_loss += loss_size.item()\n",
        "            \n",
        "            #Print every 10th batch of an epoch\n",
        "            if (i + 1) % (print_every + 1) == 0:\n",
        "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
        "                #Reset running loss and time\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "            \n",
        "        #At the end of the epoch, do a pass on the validation set\n",
        "       # total_val_loss = 0\n",
        "        #for inputs, labels in val_loader:\n",
        "            \n",
        "            #Wrap tensors in Variables\n",
        "         #   inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            #Forward pass\n",
        "          #  val_outputs = net(inputs)\n",
        "           # val_loss_size = loss(val_outputs, labels)\n",
        "            #total_val_loss += val_loss_size.data[0]\n",
        "            \n",
        "        #print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
        "        \n",
        "#print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8SYE6OQ5nnVS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "CNN = SimpleCNN()\n",
        "trainNet(CNN, batch_size=28, n_epochs=2, learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GyboUC5rSvSh",
        "colab_type": "code",
        "outputId": "33613ee1-2e31-4928-ee20-d4c283c96706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "testloader=get_test_loader(28)\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "    \n",
        "        images_test, labels_test = data\n",
        "        inputs, labels = Variable(images_test), Variable(labels_test)\n",
        "            \n",
        "        outputs=CNN(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels_test.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 9 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}